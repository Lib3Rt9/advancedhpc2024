{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Labwork 1 + 2"
      ],
      "metadata": {
        "id": "16EkXKvdJwDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S4bPeu-LJdip"
      },
      "outputs": [],
      "source": [
        "import numba\n",
        "from numba import cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect available CUDA GPU\n",
        "numba.cuda.detect()\n",
        "\n",
        "# Select GPU\n",
        "device = cuda.select_device(0)\n",
        "print(device)\n",
        "print(f\"Device name: {device.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq0oVLwvJgwZ",
        "outputId": "66030002-7219-4042-8f02-28593254fa60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0             b'Tesla T4'                              [SUPPORTED]\n",
            "                      Compute Capability: 7.5\n",
            "                           PCI Device ID: 4\n",
            "                              PCI Bus ID: 0\n",
            "                                    UUID: GPU-af936f72-170a-716a-326e-6053e93d8f54\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 32\n",
            "Summary:\n",
            "\t1/1 devices are supported\n",
            "<CUDA device 0 'b'Tesla T4''>\n",
            "Device name: b'Tesla T4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get GPU information\n",
        "my_sms = getattr(device, 'MULTIPROCESSOR_COUNT')\n",
        "my_cc = device.compute_capability"
      ],
      "metadata": {
        "id": "4cg36sn_Jpm2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get counts\n",
        "multiprocessor_count = device.MULTIPROCESSOR_COUNT\n",
        "core_count = multiprocessor_count * 64 # Tesla T4 has 64 CUDA cores per multiprocessor\n",
        "print(f\"Multiprocessor count: {multiprocessor_count}\")\n",
        "print(f\"Approximate core count: {core_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOY98bTHJr14",
        "outputId": "5a8d80d6-26d9-44b0-eaf8-6bed830f6c66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiprocessor count: 40\n",
            "Approximate core count: 2560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get memory info\n",
        "memory_info = cuda.current_context().get_memory_info()\n",
        "\n",
        "# Total and free memory in bytes\n",
        "total_memory = memory_info[1]  # The second value returned is the total memory\n",
        "print(f\"Total memory size: {total_memory / (1024**3):.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS3z2ie1Jt6N",
        "outputId": "7764d589-111d-405b-d04d-59eeda16919a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory size: 14.75 GB\n"
          ]
        }
      ]
    }
  ]
}